{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) dates should be formatted in excel to yyyy-MM-dd\n",
    "# 2) data input as excel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"//usoil.local/Production/USV/Apps/PowerBI/US AutoForce/Sales Reports/CMP/Input/current_g3x_con_DELETE2.xlsx\"\n",
    "x1 = pd.ExcelFile(filename) # check this out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = '//usoil.local/Production/USV/Apps/PowerBI/US AutoForce/Sales Reports/CMP/Incentive Requirments/GDY_CON_Incentive.txt'\n",
    "df_tierMap = pd.read_csv(filename2, sep = '\\t')\n",
    "# df_tierMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = len(x1.sheet_names)\n",
    "sheetList = x1.sheet_names\n",
    "sheetList.sort()\n",
    "# sheetList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sheet in sheetList:\n",
    "    if '1st' in sheet and 'Qtr' in sheet:\n",
    "        print('Q1 exist')\n",
    "        df1 = pd.read_excel(filename,sheet_name=sheet,header=1)\n",
    "        \n",
    "        df1.columns = df1.columns.str.replace(' ', '_')\n",
    "        df1.columns = df1.columns.str.replace('#', 'num')\n",
    "        \n",
    "        df_current = df1\n",
    "        \n",
    "    elif '2nd' in sheet and 'Qtr' in sheet:\n",
    "        print('Q2 exist')\n",
    "        df2 = pd.read_excel(filename,sheet_name=sheet,header=1)\n",
    "        df2.columns = df2.columns.str.replace(' ', '_')\n",
    "        df2.columns = df2.columns.str.replace('#', 'num')\n",
    "        \n",
    "        df_historic1 = df1.iloc[:,[1,14,15,16,17,18,19,20]]\n",
    "        df_historic1 = df_historic1.add_suffix('_Q1')\n",
    "        \n",
    "        df_current = df2\n",
    "        \n",
    "    elif '3rd' in sheet and 'Qtr' in sheet:\n",
    "        print('Q3 exist')\n",
    "        df3 = pd.read_excel(filename,sheet_name=sheet,header=1)\n",
    "        df3.columns = df3.columns.str.replace(' ', '_')\n",
    "        df3.columns = df3.columns.str.replace('#', 'num')\n",
    "        \n",
    "        df_historic2 = df2.iloc[:,[1,14,15,16,17,18,19,20]]\n",
    "        df_historic2 = df_historic2.add_suffix('_Q2')\n",
    "        \n",
    "        df_current = df3\n",
    "        \n",
    "    elif '4th' in sheet and 'Qtr' in sheet:\n",
    "        print('Q4 exist')\n",
    "        df4 = pd.read_excel(filename,sheet_name=sheet,header=1)\n",
    "        df4.columns = df4.columns.str.replace(' ', '_')\n",
    "        df4.columns = df4.columns.str.replace('#', 'num')\n",
    "            \n",
    "        df_historic3 = df3.iloc[:,[1,14,15,16,17,18,19,20]]\n",
    "        df_historic3 = df_historic3.add_suffix('_Q3')\n",
    "        \n",
    "        df_current = df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_historic3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_historic1' in locals() and 'df_historic2' in locals() and 'df_historic3' in locals():\n",
    "    df_historic = df_historic1.set_index('G3X_Common_Owner_Q1').join(\n",
    "        df_historic2.set_index('G3X_Common_Owner_Q2'),how='outer').join(\n",
    "        df_historic3.set_index('G3X_Common_Owner_Q3'),how='outer')\n",
    "    \n",
    "elif 'df_historic1' in locals() and 'df_historic2' in locals():\n",
    "    print('2 historical quarters')\n",
    "    df_historic = df_historic1.set_index('G3X_Common_Owner_Q1').join(\n",
    "        df_historic2.set_index('G3X_Common_Owner_Q2'),how='outer').assign(Incentive_Curr_Tier_Q3=0,\n",
    "        Net_Shipments_QTD_Q3=0,Units_to_Incnt_Nxt_Tier_Q3=0,Goodyear_Core_Net_Purchases_QTD_Q3=0,\n",
    "        Kelly_Net_Purchases_QTD_Q3=0,Other_Net_Purchases_QTD_Q3=0,Incentive_Payment_Q3=0)\n",
    "\n",
    "else:\n",
    "    print('1 historical quarter')\n",
    "    df_historic = df_historic1.assign(\n",
    "        Incentive_Curr_Tier_Q2=0,Net_Shipments_QTD_Q2=0,Units_to_Incnt_Nxt_Tier_Q2=0,Goodyear_Core_Net_Purchases_QTD_Q2=0,\n",
    "        Kelly_Net_Purchases_QTD_Q2=0,Other_Net_Purchases_QTD_Q2=0,Incentive_Payment_Q2=0,Incentive_Curr_Tier_Q3=0,\n",
    "        Net_Shipments_QTD_Q3=0,Units_to_Incnt_Nxt_Tier_Q3=0,Goodyear_Core_Net_Purchases_QTD_Q3=0,\n",
    "        Kelly_Net_Purchases_QTD_Q3=0,Other_Net_Purchases_QTD_Q3=0,Incentive_Payment_Q3=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tup_now = datetime.now().timetuple()\n",
    "currentYear = datetime.now().year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_currentData = os.path.getctime(filename)\n",
    "dt_currentData = datetime.fromtimestamp(ts_currentData)\n",
    "# print(dt_currentData)\n",
    "ts_incentive = os.path.getctime(filename2)\n",
    "dt_incentive = datetime.fromtimestamp(ts_incentive)\n",
    "# print(dt_incentive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculatedData = pd.DataFrame([])\n",
    "for ii in range(df_current.shape[0]):\n",
    "\n",
    "    singleCusty = df_current.iloc[[ii]].assign(QTDsum=0)\n",
    "    singleCusty.reset_index(inplace=True,drop=True)\n",
    "\n",
    "    singleCusty.QTDsum = singleCusty.Goodyear_Core_Net_Purchases_QTD + singleCusty.Kelly_Net_Purchases_QTD + singleCusty.Other_Net_Purchases_QTD\n",
    "    singleCusty_select = singleCusty[\n",
    "        ['G3X_CO_Name','num_Locations','Goodyear_Core_Net_Purchases_QTD','Kelly_Net_Purchases_QTD','Other_Net_Purchases_QTD','QTDsum']]\n",
    "    singleCusty_select = singleCusty_select.rename(index=str, columns={\n",
    "        'G3X_CO_Name':'Name','num_Locations':'numLocs','Goodyear_Core_Net_Purchases_QTD':'goodyearQTD','Kelly_Net_Purchases_QTD':'kellyQTD','Other_Net_Purchases_QTD':'dunlopQTD'})\n",
    "    excel_date = singleCusty.Last_Transaction\n",
    "\n",
    "    date_lt = datetime.fromordinal(datetime(1900, 1, 1).toordinal() + excel_date - 2)\n",
    "    tt = date_lt.timetuple()\n",
    "\n",
    "    if  tt.tm_year == currentYear:\n",
    "\n",
    "        if (tt.tm_mon == 1) | (tt.tm_mon == 2) | (tt.tm_mon == 3):\n",
    "            if ((tt.tm_year % 400 == 0) | (tt.tm_year % 4 == 0)) & (tt.tm_year % 100 != 0):\n",
    "                quarter = 1\n",
    "                daysINqtr = 91\n",
    "                print('Leap year')\n",
    "            else:\n",
    "                quarter = 1\n",
    "                daysINqtr = 90           \n",
    "        elif (tt.tm_mon == 4) | (tt.tm_mon == 5) | (tt.tm_mon == 6):\n",
    "            quarter = 2\n",
    "            daysINqtr = 91\n",
    "            subtractDays = 90          \n",
    "        elif (tt.tm_mon == 7) | (tt.tm_mon == 8) | (tt.tm_mon == 9):\n",
    "            quarter = 3\n",
    "            daysINqtr = 92\n",
    "            subtractDays = 90 + 91\n",
    "        else:\n",
    "            quarter = 4\n",
    "            daysINqtr = 92\n",
    "            subtractDays = 90 + 91 + 92\n",
    "        \n",
    "        numDays = tt.tm_yday - subtractDays # get number of days\n",
    "\n",
    "        estimatedTires = np.floor((singleCusty.QTDsum/(numDays/daysINqtr))).values\n",
    "        numLocations = singleCusty.num_Locations.values\n",
    "        \n",
    "        if   (estimatedTires >= (df_tierMap.iloc[1,4] )) & (estimatedTires <= (df_tierMap.iloc[1,5])):\n",
    "            tierType = 1\n",
    "        elif (estimatedTires >= (df_tierMap.iloc[2,4] )) & (estimatedTires <= (df_tierMap.iloc[2,5])):\n",
    "            tierType = 2\n",
    "        elif (estimatedTires >= (df_tierMap.iloc[3,4] )) & (estimatedTires <= (df_tierMap.iloc[3,5])):\n",
    "            tierType = 3\n",
    "        elif (estimatedTires >= (df_tierMap.iloc[4,4])):\n",
    "            tierType = 4\n",
    "        else:\n",
    "            tierType = 0\n",
    "        \n",
    "        if tierType < 4:\n",
    "            tierUP = tierType + 1\n",
    "        else:\n",
    "            tierUP = 4\n",
    "        \n",
    "        # floor to underestimate estimated tires\n",
    "        goodYR_est_tires = np.floor((singleCusty.Goodyear_Core_Net_Purchases_QTD/(numDays/daysINqtr)).values)\n",
    "        goodYR_est_tires_rebate = goodYR_est_tires * df_tierMap.iloc[tierType,1]\n",
    "        goodYR_prop = singleCusty_select.goodyearQTD/singleCusty_select.QTDsum\n",
    "        # ceil to make sure the customer surpasses the minimal 1up tire threshold\n",
    "        goodYR_1up_tires = np.ceil((goodYR_prop*df_tierMap.iloc[tierUP,4]*numLocations).values)\n",
    "        goodYR_1up_tires_rebate = goodYR_1up_tires * df_tierMap.iloc[tierUP,1]\n",
    "        \n",
    "        kelly_est_tires = np.floor((singleCusty.Kelly_Net_Purchases_QTD/(numDays/daysINqtr)).values)\n",
    "        kelly_est_tires_rebate = kelly_est_tires * df_tierMap.iloc[tierType,2]\n",
    "        kelly_prop = singleCusty_select.kellyQTD/singleCusty_select.QTDsum\n",
    "        kelly_1up_tires = np.ceil((kelly_prop*df_tierMap.iloc[tierUP,4]*numLocations).values)\n",
    "        kelly_1up_tires_rebate = kelly_1up_tires * df_tierMap.iloc[tierUP,2]\n",
    "        \n",
    "        dunlop_est_tires = np.floor((singleCusty.Other_Net_Purchases_QTD/(numDays/daysINqtr)).values)\n",
    "        dunlop_est_tires_rebate = dunlop_est_tires * df_tierMap.iloc[tierType,3]\n",
    "        dunlop_prop = singleCusty_select.dunlopQTD/singleCusty_select.QTDsum\n",
    "        dunlop_1up_tires = np.ceil((dunlop_prop*df_tierMap.iloc[tierUP,4]*numLocations).values)\n",
    "        dunlop_1up_tires_rebate = dunlop_1up_tires * df_tierMap.iloc[tierUP,3]\n",
    "        \n",
    "        total_est_tires = goodYR_est_tires + kelly_est_tires + dunlop_est_tires\n",
    "        total_est_dollars = goodYR_est_tires_rebate+kelly_est_tires_rebate+dunlop_est_tires_rebate\n",
    "        total_1up_dollars = goodYR_1up_tires_rebate+kelly_1up_tires_rebate+dunlop_1up_tires_rebate\n",
    "        total_1up_tires = goodYR_1up_tires+kelly_1up_tires+dunlop_1up_tires\n",
    "        \n",
    "        if estimatedTires > total_1up_tires:\n",
    "            goodYR_1up_tires = goodYR_est_tires\n",
    "            kelly_1up_tires = kelly_est_tires\n",
    "            dunlop_1up_tires = dunlop_est_tires\n",
    "            total_1up_tires = estimatedTires\n",
    "            \n",
    "            goodYR_1up_tires_rebate = goodYR_est_tires_rebate\n",
    "            kelly_1up_tires_rebate = kelly_est_tires_rebate\n",
    "            dunlop_1up_tires_rebate = dunlop_est_tires_rebate\n",
    "            total_1up_dollars = total_est_dollars\n",
    "\n",
    "        range_dollars_ll = ((total_1up_tires*df_tierMap.iloc[tierUP,3]))#.values\n",
    "        range_dollars_ul = ((total_1up_tires*df_tierMap.iloc[tierUP,1]))#.values\n",
    "        \n",
    "        tempData = pd.DataFrame(\n",
    "            {'estimated_tier':tierType,\n",
    "             'GY_est_tires':goodYR_est_tires, 'Kelly_est_tires':kelly_est_tires, 'Dunlop_est_tires':dunlop_est_tires, 'current_est_tires':total_est_tires*numLocations,\n",
    "             'GY_est_rebate':goodYR_est_tires_rebate, 'Kelly_est_rebate':kelly_est_tires_rebate, 'Dunlop_est_rebate':dunlop_est_tires_rebate,\n",
    "             'total_est_rebate': total_est_dollars,'Up_tier':tierUP,\n",
    "             'GY_up_tires':goodYR_1up_tires, 'Kelly_up_tires':kelly_1up_tires, 'Dunlop_up_tires':dunlop_1up_tires, 'total_up_tires':total_1up_tires,\n",
    "             'GY_up_rebate':goodYR_1up_tires_rebate, 'Kelly_up_rebate':kelly_1up_tires_rebate, 'Dunlop_up_rebate':dunlop_1up_tires_rebate,\n",
    "             'total_up_rebate':total_1up_dollars,\n",
    "             'range_lower':range_dollars_ll, 'range_upper':range_dollars_ul,'period': quarter, 'grain': 'Quarter'})\n",
    "        calculatedData = calculatedData.append(tempData)\n",
    "    else:\n",
    "        range_dollars_ll = (df_tierMap.iloc[1,3] * df_tierMap.iloc[1,4])\n",
    "        range_dollars_ul = (df_tierMap.iloc[1,1] * df_tierMap.iloc[1,4]) \n",
    "        tempData = pd.DataFrame(\n",
    "            {'estimated_tier':0,\n",
    "             'GY_est_tires':0, 'Kelly_est_tires':0, 'Dunlop_est_tires':0, 'current_est_tires':0, \n",
    "             'GY_est_rebate':0, 'Kelly_est_rebate':0, 'Dunlop_est_rebate':0,\n",
    "             'total_est_rebate': 0, 'Up_tier':1,\n",
    "             'GY_up_tires':0, 'Kelly_up_tires':0, 'Dunlop_up_tires':0, 'total_up_tires':0,\n",
    "             'GY_up_rebate':0, 'Kelly_up_rebate':0, 'Dunlop_up_rebate':0,\n",
    "             'total_up_rebate':0,\n",
    "             'range_lower':[range_dollars_ll], 'range_upper':[range_dollars_ul],'period': quarter, 'grain': 'Quarter'})\n",
    "        calculatedData = calculatedData.append(tempData)\n",
    "###########################################################################################################################        \n",
    "calculatedData = calculatedData.reset_index(drop=True)\n",
    "finalData = pd.concat([calculatedData,df_current], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = finalData.replace([np.inf, -np.inf], np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '//usoil.local/Production/USV/Apps/PowerBI/US AutoForce/Sales Reports/CMP/python_csv_output/'\n",
    "writeFilename = path + 'CMP_G3X_CON.csv'\n",
    "finalData.to_csv(writeFilename, index=False)\n",
    "writeFilename_archive = path + 'csv_archive/' + str(tup_now.tm_year) + '_' + str(tup_now.tm_mon).zfill(2) \\\n",
    "                        + '_' + str(tup_now.tm_mday).zfill(2) + '_' + 'CMP_G3X_CON_' \\\n",
    "                        + str(tup_now.tm_hour).zfill(2) + str(tup_now.tm_min).zfill(2) + str(tup_now.tm_sec).zfill(2) \\\n",
    "                        + '.csv'\n",
    "finalData.to_csv(writeFilename_archive, index=False)\n",
    "\n",
    "path = '//usoil.local/Production/USV/Apps/PowerBI/US AutoForce/Sales Reports/CMP/python_csv_output/csv_quarter_history/'\n",
    "writeFilename = path + 'CMP_G3X_CON_historic.csv'\n",
    "df_historic.to_csv(writeFilename, index=False)\n",
    "writeFilename_archive = path + 'csv_historic_archive/' + str(tup_now.tm_year) + '_' + str(tup_now.tm_mon).zfill(2) \\\n",
    "                        + '_' + str(tup_now.tm_mday).zfill(2) + '_' + 'CMP_G3X_CON_historic_' \\\n",
    "                        + str(tup_now.tm_hour).zfill(2) + str(tup_now.tm_min).zfill(2) + str(tup_now.tm_sec).zfill(2) \\\n",
    "                        + '.csv'\n",
    "df_historic.to_csv(writeFilename_archive, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
